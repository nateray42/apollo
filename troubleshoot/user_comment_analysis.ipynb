{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49c2fcc4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import prawcore\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import os\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "from itertools import chain, combinations\n",
    "from more_itertools import pairwise\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, date\n",
    "\n",
    "\n",
    "from spacy import load\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=r\"\\[W008\\]\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6dcd79",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "path = 'data'\n",
    "user_dir = 'user_data'\n",
    "reddit = praw.Reddit(\n",
    "    client_id='4bDjCY6y8ncrc3kLrBbpBg',\n",
    "    client_secret='zPHZKfk9S666S9IxR5HtvkZ83ufNxw',\n",
    "    user_agent='webcrawler created for IS596'\n",
    ")\n",
    "\n",
    "nlp = load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f96ec0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    norm_text = []\n",
    "\n",
    "    for token in text:\n",
    "        if not token.is_punct and not token.is_stop and not token.is_space:\n",
    "            norm_text.append(token.lemma_.lower())\n",
    "\n",
    "    norm_text = ' '.join(norm_text)\n",
    "    norm_text = re.sub(r'(?:^| )\\w(?:$| )', ' ', norm_text).strip()  # removes single characters\n",
    "    norm_text = re.sub(r'[^a-zA-Z0-9 ]', '', norm_text)\n",
    "    \n",
    "    return norm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aac2dd46",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_user_status(path):\n",
    "    try:\n",
    "        user.is_suspended\n",
    "        user_status = 'suspended'\n",
    "    except AttributeError:\n",
    "        user_status = 'active'\n",
    "    except:\n",
    "        user_status = 'deleted'\n",
    "    return user_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415418ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_sim(sent_1, sent_2):\n",
    "    l1 = []; l2 = []\n",
    "    \n",
    "    sent_1 = set(sent_1.split(' '))\n",
    "    sent_2 = set(sent_2.split(' '))\n",
    "    \n",
    "    rvector = sent_1.union(sent_2)\n",
    "    \n",
    "    for word in rvector:\n",
    "        if word in sent_1: l1.append(1)\n",
    "        else: l1.append(0)\n",
    "        if word in sent_2: l2.append(1)\n",
    "        else: l2.append(0)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(rvector)):\n",
    "        count += l1[i] * l2[i]\n",
    "    cosine = count/float((sum(l1) * sum(l2))**.5)\n",
    "    \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d0c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(vec1, vec2):\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n",
    "    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n",
    "\n",
    "\n",
    "def text_to_vector(text):\n",
    "    WORD = re.compile(r\"\\w+\")\n",
    "    words = WORD.findall(text)\n",
    "    return Counter(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d328ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sentences:\n",
      "the fox jumped over the log\n",
      "the dog sat on the log\n",
      "\n",
      "normalized sentences:\n",
      "fox jump log\n",
      "dog sit log\n",
      "\n",
      "cosine_function: 0.3333333333333333\n",
      "spacy similarity function: 0.6839218144112934\n"
     ]
    }
   ],
   "source": [
    "sent_1 = \"the fox jumped over the log\"\n",
    "sent_2 = \"the dog sat on the log\"\n",
    "\n",
    "print('original sentences:')\n",
    "print(sent_1)\n",
    "print(sent_2)\n",
    "print()\n",
    "\n",
    "sent_1 = normalize(nlp(sent_1))\n",
    "sent_2 = normalize(nlp(sent_2))\n",
    "\n",
    "vec_1 = text_to_vector(sent_1)\n",
    "vec_2 = text_to_vector(sent_2)\n",
    "print('normalized sentences:')\n",
    "print (sent_1)\n",
    "print (sent_2)\n",
    "print()\n",
    "\n",
    "print(f'cosine_function: {calculate_cosine_sim(sent_1, sent_2)}')\n",
    "# print(f'cosine_function_2: {get_cosine(vec_1, vec_2)}')\n",
    "\n",
    "sent_1 = nlp(sent_1)\n",
    "sent_2 = nlp(sent_2)\n",
    "print(f'spacy similarity function: {sent_1.similarity(sent_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c12675",
   "metadata": {},
   "source": [
    "## Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7db364f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [4:37:15<00:00, 16.64s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 username  avg_comment_similarity avg_comment_time_interval  \\\n",
      "0        ninernetneepneep                0.485185           0 days 02:25:30   \n",
      "1      Imdatingstaceysmom                0.478584           6 days 21:24:15   \n",
      "2               dirtyALEK                0.462610           1 days 10:16:53   \n",
      "3        AlpacaWarMachine                0.332241           5 days 13:34:20   \n",
      "4            AegonTheBest                0.267938          13 days 14:42:18   \n",
      "..                    ...                     ...                       ...   \n",
      "649         RoundSimbacca                0.706914           0 days 00:37:46   \n",
      "650            raydiculus                0.402227           0 days 01:35:18   \n",
      "651                geekxp                0.557835           1 days 23:03:29   \n",
      "652  Entire_Proposal_1318                0.397180          12 days 10:02:47   \n",
      "653          skinnykid108                0.250920           1 days 00:12:07   \n",
      "\n",
      "    avg_reply_speed  \n",
      "0   0 days 09:43:20  \n",
      "1   0 days 09:19:36  \n",
      "2   0 days 03:50:48  \n",
      "3   0 days 00:19:51  \n",
      "4   0 days 05:25:20  \n",
      "..              ...  \n",
      "649 0 days 02:08:53  \n",
      "650 0 days 12:52:15  \n",
      "651 0 days 02:42:20  \n",
      "652 0 days 09:50:20  \n",
      "653 0 days 04:30:42  \n",
      "\n",
      "[654 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [4:51:42<00:00, 17.50s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                username  avg_comment_similarity avg_comment_time_interval  \\\n",
      "0       XxSpruce_MoosexX                0.479386           0 days 05:18:37   \n",
      "1    Wrong-Paramedic7489                0.284503           0 days 05:25:42   \n",
      "2      renaissancetrader                0.319681           0 days 19:24:59   \n",
      "3     groupthinkhivemind                0.475405           0 days 15:13:19   \n",
      "4               Fatguy73                0.290340           1 days 03:21:10   \n",
      "..                   ...                     ...                       ...   \n",
      "697      ZachMorrisT1000                0.407356           0 days 08:14:18   \n",
      "698           cRIPtoCITY                0.328947           0 days 22:56:49   \n",
      "699           portoroc86                0.508008           0 days 02:45:31   \n",
      "700            mrforrest                0.448366           2 days 19:00:07   \n",
      "701             Colosphe                0.513201           0 days 10:31:55   \n",
      "\n",
      "     avg_reply_speed  \n",
      "0    0 days 02:13:56  \n",
      "1    0 days 09:33:12  \n",
      "2    0 days 06:02:34  \n",
      "3    0 days 06:55:24  \n",
      "4    0 days 07:30:48  \n",
      "..               ...  \n",
      "697  0 days 05:01:53  \n",
      "698 13 days 16:35:29  \n",
      "699  0 days 08:44:17  \n",
      "700  0 days 04:49:24  \n",
      "701  0 days 04:34:40  \n",
      "\n",
      "[702 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 645/1000 [3:30:42<1:03:35, 10.75s/it] C:\\Users\\ray\\AppData\\Local\\Temp/ipykernel_328000/2913844110.py:62: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  time_data = pd.Series(time_intervals)\n",
      "C:\\Users\\ray\\AppData\\Local\\Temp/ipykernel_328000/2913844110.py:63: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  avg_time_diff = (time_data.sum()/len(time_data)).round('1s')\n",
      " 64%|██████▍   | 645/1000 [3:30:47<1:56:01, 19.61s/it]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_328000/2913844110.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                     \u001b[0mtime_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_intervals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                     \u001b[0mavg_time_diff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'1s'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                     \u001b[0mresponse_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse_intervals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "for filename in os.scandir('data'):\n",
    "    if filename.is_file():\n",
    "        \n",
    "        file_df = pd.read_csv(filename)\n",
    "        user_names = file_df.author\n",
    "        users_df = pd.DataFrame(columns=['user_name', 'comment_simularity'])\n",
    "        rows = []\n",
    "        \n",
    "        for user_name in tqdm(user_names[:1000]):\n",
    "            user_dict = {}\n",
    "            user_dict['username'] = user_name\n",
    "            user = reddit.redditor(user_name)\n",
    "            \n",
    "            if get_user_status(user) == 'active' and str(user_name) not in 'nan': # checks that user isn't suspended/deleted\n",
    "                if not user.is_mod: #ignore mods\n",
    "                    \n",
    "                    comment_array = []\n",
    "                    timestamps = []\n",
    "                    reply_timestamps = []\n",
    "                    \n",
    "                    try:\n",
    "                        for this_comment in user.comments.new(limit=10):\n",
    "                            \n",
    "                            parent_comment_id = this_comment.parent_id\n",
    "                            if parent_comment_id.startswith('t3'):\n",
    "                                parent_comment_id = parent_comment_id[3:]\n",
    "                                parent = reddit.submission(parent_comment_id)\n",
    "                            else:\n",
    "                                parent = reddit.comment(parent_comment_id)\n",
    "                            \n",
    "                            parent_timestamp = datetime.fromtimestamp(parent.created_utc)\n",
    "                            comment_timestamp = datetime.fromtimestamp(this_comment.created_utc)\n",
    "                            \n",
    "                            comment_array.append(this_comment.body)\n",
    "                            timestamps.append(comment_timestamp)\n",
    "                            reply_timestamps.append((parent_timestamp, comment_timestamp))\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "                        \n",
    "                    for i in range(len(comment_array)):\n",
    "                        comment_array[i] = normalize(nlp((comment_array[i]))) # normalizes comment but leaves as string\n",
    "                        comment_array[i] = nlp(normalize(nlp((comment_array[i])))) # this normalizes comment and wraps in nlp\n",
    "                        \n",
    "                    comment_similarities = []\n",
    "                    time_intervals = []\n",
    "                    response_intervals = []\n",
    "\n",
    "                    for sent_1, sent_2 in combinations(comment_array, 2):\n",
    "                        \n",
    "#                         comment_similarities.append(calculate_cosine_sim(sent_1, sent_2)) checks cosine simularity of each comment against the next \n",
    "                        comment_similarities.append(sent_1.similarity(sent_2)) # nlp similiarity\n",
    "                    \n",
    "                    successive_times = list(pairwise(timestamps))\n",
    "                    for pair in successive_times: # calculates the intervals between user's comments\n",
    "                        time_intervals.append(abs(pair[0] - pair[1]))\n",
    "                        \n",
    "                    for pair in reply_timestamps:\n",
    "                        response_intervals.append(abs(pair[1] - pair[0]))# calculates how quickly a comment replied to its parent\n",
    "                        \n",
    "                    time_data = pd.Series(time_intervals)\n",
    "                    avg_time_diff = (time_data.sum()/len(time_data)).round('1s')\n",
    "                    \n",
    "                    response_data = pd.Series(response_intervals)\n",
    "                    avg_reply_speed = (response_data.sum()/len(response_data)).round('1s')\n",
    "                    \n",
    "                    try:\n",
    "                        avg_comment_similarity = sum(comment_similarities)/len(comment_similarities)\n",
    "                    except ZeroDivisionError:\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                        continue\n",
    "                    \n",
    "                    user_dict['avg_comment_similarity'] = avg_comment_similarity # formating dict\n",
    "                    user_dict['avg_comment_time_interval'] = avg_time_diff\n",
    "                    user_dict['avg_reply_speed'] = avg_reply_speed\n",
    "\n",
    "                    rows.append(user_dict) \n",
    "\n",
    "        users_df = pd.DataFrame.from_dict(rows, orient='columns')\n",
    "        print(users_df)\n",
    "        \n",
    "        filename = str(filename)\n",
    "        \n",
    "        if filename.startswith(\"<DirEntry 'comment\"):\n",
    "            users_df.to_csv(os.path.join(f'{path}/{user_dir}', f'users_{filename[19:-2]}'), index=False)\n",
    "\n",
    "        if filename.startswith(\"<DirEntry 'submission\"):\n",
    "            users_df.to_csv(os.path.join(f'{path}/{user_dir}', f'users_{filename[22:-2]}'), header=False, index=False, mode='a')\n",
    "                               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a6e2d",
   "metadata": {},
   "source": [
    "## Troubleshoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4f8a981",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment id: iyheu0h\n",
      "comment timestamp: 2022-12-01 06:37:35\n",
      "Just FYI it is a mandatory recount as required by state law due to the margin. It is not expected to change the results.\n",
      "parent_comment_id: z9mqfx\n",
      "parent timestamp: 2022-12-01 06:34:01\n",
      "\n",
      "comment id: iyg4kiw\n",
      "comment timestamp: 2022-11-30 21:22:00\n",
      "People just voting based on the Ror D beside the name\n",
      "parent_comment_id: t1_iycv05a\n",
      "parent timestamp: 2022-11-30 07:36:18\n",
      "\n",
      "comment id: iyg4gb2\n",
      "comment timestamp: 2022-11-30 21:21:04\n",
      "Did they not do this during the normal election?\n",
      "parent_comment_id: z8raxt\n",
      "parent timestamp: 2022-11-30 07:19:03\n",
      "\n",
      "comment id: iyg482w\n",
      "comment timestamp: 2022-11-30 21:19:15\n",
      "Didn't some Dems do also? No one is looking great on this.\n",
      "parent_comment_id: z98nw4\n",
      "parent timestamp: 2022-11-30 18:31:50\n",
      "\n",
      "comment id: iyg430h\n",
      "comment timestamp: 2022-11-30 21:18:06\n",
      "So where are the studies for blue states and what are the death rate of unaffiliated voters?\n",
      "This is a serious question. Shouldn't you have a control group ?\n",
      "parent_comment_id: z8zz6d\n",
      "parent timestamp: 2022-11-30 13:04:10\n",
      "\n",
      "reply times:\n",
      "(datetime.datetime(2022, 12, 1, 6, 34, 1), datetime.datetime(2022, 12, 1, 6, 37, 35))\n",
      "(datetime.datetime(2022, 11, 30, 7, 36, 18), datetime.datetime(2022, 11, 30, 21, 22))\n",
      "(datetime.datetime(2022, 11, 30, 7, 19, 3), datetime.datetime(2022, 11, 30, 21, 21, 4))\n",
      "(datetime.datetime(2022, 11, 30, 18, 31, 50), datetime.datetime(2022, 11, 30, 21, 19, 15))\n",
      "(datetime.datetime(2022, 11, 30, 13, 4, 10), datetime.datetime(2022, 11, 30, 21, 18, 6))\n",
      "\n",
      "response intervals:\n",
      "0:03:34\n",
      "13:45:42\n",
      "14:02:01\n",
      "2:47:25\n",
      "8:13:56\n"
     ]
    }
   ],
   "source": [
    "user = reddit.redditor('SignificantTrout')\n",
    "comment_array = []\n",
    "timestamps = []\n",
    "reply_times = []\n",
    "\n",
    "for this_comment in user.comments.new(limit=5):\n",
    "                            \n",
    "    comment_timestamp = datetime.fromtimestamp(this_comment.created_utc)\n",
    "    print(f'comment id: {this_comment.id}')\n",
    "    print(f'comment timestamp: {comment_timestamp}')\n",
    "    parent_comment_id = this_comment.parent_id\n",
    "    \n",
    "    print(this_comment.body)\n",
    "    if parent_comment_id.startswith('t3'):\n",
    "        parent_comment_id = parent_comment_id[3:]\n",
    "        parent = reddit.submission(parent_comment_id)\n",
    "        print(f'parent_comment_id: {parent.id}')\n",
    "    else:\n",
    "        parent = reddit.comment(parent_comment_id)\n",
    "        print(f'parent_comment_id: {parent.id}')\n",
    "    try:\n",
    "        parent_id = parent.id.lstrip('t3_')\n",
    "        parent_timestamp = datetime.fromtimestamp(parent.created_utc)\n",
    "        print(f'parent timestamp: {parent_timestamp}')\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print()\n",
    "        continue\n",
    "    comment_array.append(this_comment.body)\n",
    "    timestamps.append(comment_timestamp)\n",
    "    reply_times.append((parent_timestamp, comment_timestamp))\n",
    "\n",
    "print(f'reply times:')\n",
    "for reply in reply_times:\n",
    "    print(reply)\n",
    "response_intervals = []\n",
    "for pair in reply_times:\n",
    "    response_intervals.append(abs(pair[1] - pair[0]))\n",
    "\n",
    "print()\n",
    "print('response intervals:')\n",
    "for response in response_intervals:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ee9fab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1669898041.0\n"
     ]
    }
   ],
   "source": [
    "post = reddit.submission('z9mqfx')\n",
    "\n",
    "print(post.created_utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c7bfe36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cosine_sim(\"the dog sat on the log\", \"the fox jumped over the log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7865b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
